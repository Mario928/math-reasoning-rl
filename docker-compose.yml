services:
  verl:
    image: verlai/verl:vllm011.latest
    container_name: verl
    runtime: nvidia
    shm_size: 32gb
    entrypoint: ""
    volumes:
      - hf_cache:/root/.cache/huggingface
      - models:/app/models
      - datasets:/app/data
      - ./run_ppo.sh:/workspace/run_ppo.sh
    command: >
      bash -c "git clone https://github.com/volcengine/verl /tmp/verl 2>/dev/null;
               pip install --no-deps -e /tmp/verl -q;
               pip install 'numpy>=2.0,<2.3' -q;
               sleep infinity"

  jupyter:
    image: pytorch/pytorch:2.7.1-cuda12.6-cudnn9-devel
    container_name: jupyter
    runtime: nvidia
    shm_size: 32gb
    ports:
      - "8888:8888"
    volumes:
      - hf_cache:/root/.cache/huggingface
      - models:/app/models
      - ./notebooks:/workspace/notebooks
    command: >
      bash -c "pip install jupyter transformers datasets accelerate peft trl mlflow==3.9.0 &&
               jupyter notebook --ip=0.0.0.0 --port=8888 --no-browser --allow-root --NotebookApp.token=''"

  mlflow:
    image: ghcr.io/mlflow/mlflow:v3.9.0
    container_name: mlflow
    ports:
      - "5000:5000"
    environment:
      - MLFLOW_SERVER_ALLOWED_HOSTS=*
    volumes:
      - mlflow_data:/mlflow
    command: mlflow server --host 0.0.0.0 --port 5000 --backend-store-uri /mlflow

volumes:
  hf_cache:
  models:
  datasets:
  mlflow_data:
